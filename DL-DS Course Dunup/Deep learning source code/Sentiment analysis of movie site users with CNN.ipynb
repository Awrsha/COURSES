{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) بررسی دیتاست نظرات کاربران سایت IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = numpy.concatenate((X_train, X_test), axis=0)\n",
    "y = numpy.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "# خلاصه کردن اندازه رکوردها\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# مشخص کردن تعداد کلاس ها\n",
    "print(\"Classes: \")\n",
    "print(numpy.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# مشخص کردن تعداد لغات منحصر بفرد\n",
    "print(\"Number of words: \")\n",
    "print(len(numpy.unique(numpy.hstack(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### میانگین طول نظرات (از چند واژه در هر نظر استفاده شده است)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dfXDV1b3v8ffXQMIRlRAFmks8F/VyzwmkldIUnCnjGB0e1I7a2mMN3mOUTKkeYai0BdrcGXxoLNLjA6KV6k1acGqo0/aoc0EoAk4HW1Qs0SJpL6hYoilCA1ZpQ0L43j/22unOE3nO3tm/z2vmN3vv7/79dtaS7Tcr67cezN0REZFoOCPZBRARkcGjpC8iEiFK+iIiEaKkLyISIUr6IiIRMizZBTid8847zydMmJDsYkgae/3114+4+5jB/rn6bstAOt33OqWT/oQJE9i1a1eyiyFpzMzeS8bP1XdbBtLpvtfq3hERiRAlfRGRCFHSFxGJECV9EZEIUdIXEYmQLpO+mZ1vZtvNrMbM3jKzRSF+l5m9b2bV4bgq4ZrvmNl+M/ujmc1OiM8Jsf1mtmxgqhRNVVVVFBQUkJGRQUFBAVVVVckukoikoO4M2TwJfNPdf2dmZwOvm9mW8N5D7v6fiSeb2STgRmAy8N+AF83sf4a3HwNmArXAa2b2vLvv7Y+KRFlVVRVlZWVUVFQwY8YMduzYQWlpKQDFxcVJLp2IpJIuW/ruXufuvwvPPwZqgPGnueRaYL27n3D3d4H9wLRw7Hf3d9y9EVgfzpU+Ki8vp6KigqKiIoYPH05RUREVFRWUl5cnu2hJ19DQwLRp07j44ouZPHkyy5cvB+CWW27hggsuAJgU/lKdAmAxj4S/Rt80s6nxzzKzEjPbF46ShPjnzOz34ZpHzMwGuZoi3dajPn0zmwB8FnglhBaE/zEqzWx0iI0HDiZcVhtincXb/oz5ZrbLzHYdPny4J8WLrJqaGmbMmNEqNmPGDGpqapJUotSRlZXFtm3beOONN6iurmbTpk3s3LkTgB/84AcAe919irtXh0uuBCaGYz7wOICZ5QDLgenEGjDLE77zj4dz49fNGZTKifRCt2fkmtlZwC+Ab7j7X83sceBewMPjA8A8oKNWjtPxL5h2O7i4+xPAEwCFhYXa4aUb8vPz2bFjB0VFRS2xHTt2kJ+fn8RSpQYz46yzzgKgqamJpqYmumiIXwus89juQjvNLNvMcoHLgC3uXh8+dwswx8xeAs5x99+G+DrgOuCF3pZ5wrINvbruwIqre/sjJUK61dI3s+HEEv5P3f2XAO5+yN2b3f0U8CSx1g/EWvDnJ1yeB3xwmrj0UVlZGaWlpWzfvp2mpia2b99OaWkpZWVlyS5aSmhubmbKlCmMHTuWmTNnMn36dID4f59JZvaQmWWF03v6l+r48LxtvB39FSupoMuWfuifrABq3P3BhHiuu9eFl18C9oTnzwNPm9mDxG7kTgReJfYXwEQzuwB4n9jN3rn9VZEoi9+sXbhwITU1NeTn51NeXq6buEFGRgbV1dUcO3aML33pS+zZs4fvf//7fOpTn+KMM86oAXKApcA9dP6Xak/j7YP6K1ZSQHe6d74A/DvwezOL93t+FygON78cOAB8HcDd3zKzZ4C9xEb+3OHuzQBmtgDYDGQAle7+Vj/WJdKKi4uV5LuQnZ3NZZddxqZNm/jWt74VDzvwYyAeON1fqpe1ib8U4nkdnC+SkrpM+u6+g45bMxtPc0050G7oiLtvPN11Iv3t8OHDDB8+nOzsbP7+97/z4osvsnTpUurq6sjNzY2fdh2t/1JdYGbrid20/cjd68xsM3Bfws3bWcB33L3ezD42s0uIDXC4GVg9aBUU6aGUXlpZpK/q6uooKSmhubmZU6dOccMNN/DFL36Ryy+/nNCvPhn4A3BbuGQjcBWxocZ/A24FCMn9XuC1cN498Zu6wO3AT4B/InYDt9c3cUUGmpK+pLXPfOYz7N69u11827ZtAJjZW+7+v+LxMGrnjo4+y90rgcoO4ruAgn4qssiA0to7IiIRoqQvIhIhSvoiIhGipJ8mtMqmiHSHbuSmAa2yKSLdpZZ+GtAqmyLSXUr6aUCrbIpIdynpp4H4KpuJtMqmiHREST8NaJVNEeku3chNA1plU0S6S0k/TWiVTRHpDnXviIhEiJK+iEiEKOmLiESIkr6ISIQo6YuIRIiSvohIhCjpi4hEiJK+iEiEKOmnCa2nLyLdoaSfBqqqqli0aBHHjx/H3Tl+/DiLFi1S4g8aGhqYNm0aF198MZMnT2b58uUAvPvuuwD/amb7zOxnZpYJYGZZ4fV+M3vFzCbEP8vMvhPifzSz2QnxOSG238yWDWoFRXpAST8NLFmyhIyMDCorKzlx4gSVlZVkZGSwZMmSZBctJWRlZbFt2zbeeOMNqqur2bRpEzt37mTp0qUAh9x9InAUKA2XlAJH3f1/AA8B9wOY2STgRmAyMAf4oZllmFkG8BhwJTAJKA7niqQcJf00UFtby7p161ptorJu3Tpqa2uTXbSUYGacddZZADQ1NdHU1ISZsW3bNogle4C1wHXh+bXhNcDPgSvMzEJ8vbufcPd3gf3AtHDsd/d33L0RWB/OFUk5SvoSCc3NzUyZMoWxY8cyc+ZMLrroIrKzsxNPqQXGh+fjgYMA7n4S+Ag4NzHe5prO4iIpR0k/DeTl5VFSUtJqPf2SkhLy8vKSXbSUkZGRQXV1NbW1tbz66qud7Srm4dE6ea+n8VbMbL6Z7TKzXYcPH+5u0UX6lZJ+Gli5ciUnT55k3rx5jBgxgnnz5nHy5ElWrlyZ7KKlnOzsbC677DJ27tzJsWPHEt/KAz4Iz2uB8wHMbBgwCqhPjLe5prN4K+7+hLsXunvhmDFj+qlGIj2jpJ8GiouLWbVqFSNHjgRg5MiRrFq1SuvrB4cPH25J8H//+9958cUXyc/Pp6ioCGB0OK0EeC48fz68BvgKsM3dPcRvDKN7LgAmAq8CrwETzeyCMALoxnCuSMrRJippQpuodK6uro6SkhKam5s5deoUN9xwA1/84heZNGkSP//5zz9lZvuB3UBFuKQCeCrE64klcdz9LTN7BtgLnATucPdmADNbAGwGMoBKd39rcGsp0j1dJn0zOx9YB3wKOAU84e6rzCwH+BkwATgA3ODuR8Moh1XAVcDfgFvc/Xfhs0qA/x0++nvuvhaRAfaZz3yG3bt3t4tfeOGFADXuXpgYd/cG4N86+ix3LwfKO4hvBDb2R3lFBlJ3undOAt9093zgEuCOMAZ5GbA1jHHeGl5DbKzyxHDMBx4HCL8klgPTiQ1xW25moxERkUHTZdJ397p4S93dPwZqiA1HSxzL3HaM8zqP2Qlkm1kuMBvY4u717n4U2EJsgouIiAySHt3IDdPRPwu8Aoxz9zqI/WIAxobTNJZZRCRFdTvpm9lZwC+Ab7j7X093agcxjWUWEUkB3Ur6ZjacWML/qbv/MoQPhW4bwuOHIa6xzCIiKarLpB9G41QQG+XwYMJbiWOZ245xvtliLgE+Ct0/m4FZZjY63MCdFWIiIjJIujNO/wvAvwO/N7PqEPsusAJ4xsxKgT/xjyFuG4kN19xPbMjmrQDuXm9m9xKbyAJwj7vX90stRESkW7pM+u6+g4774wGu6OB8B+7o5LMqgcqeFFBERPqPlmEQEYkQJX0RkQhR0hcRiRAl/TSxcOFCRowYgZkxYsQIFi5cmOwiiUgKUtJPAwsXLmTNmjXcd999HD9+nPvuu481a9Yo8YtIO0r6aeDJJ5/k/vvvZ/HixZx55pksXryY+++/nyeffDLZRRORFKOknwZOnDjBbbfd1ip22223ceLEiSSVSERSlZJ+GsjKymLNmjWtYmvWrCErKytJJRKRVKWds9LA1772NZYuXQrEWvhr1qxh6dKl7Vr/IiJK+mlg9erVAHz3u9/lm9/8JllZWdx2220tcRGROCX9NLF69WoleRHpkvr0RUQiRElfRCRClPTTRFVVFQUFBWRkZFBQUEBVVVWyi5QSDh48SFFREfn5+UyePJlVq1YBcNdddzF+/HiASWZWbWZXxa8xs++Y2X4z+6OZzU6Izwmx/Wa2LCF+gZm9Ymb7zOxnZpY5iFUU6REl/TRQVVVFWVkZq1evpqGhgdWrV1NWVqbEDwwbNowHHniAmpoadu7cyWOPPcbevXsBuPPOOwH2uvsUd98IYGaTgBuBycAc4IdmlmFmGcBjwJXAJKA4nAtwP/CQu08EjgKlg1hFkR5R0k8D5eXlzJ07t2X9nYULFzJ37lzKy8uTXbSky83NZerUqQCcffbZ5Ofn8/7775/ukmuB9e5+wt3fJbYZ0LRw7Hf3d9y9EVgPXBt2lrsc+Hm4fi1w3cDURqTvlPTTwN69e3n66adbtfSffvrplhatxBw4cIDdu3czffp0AB599FGIde9Uhi08AcYDBxMuqw2xzuLnAsfc/WSbeDtmNt/MdpnZrsOHD/dTrUR6Rkk/DWRmZrJgwQKKiooYPnw4RUVFLFiwgMxMdS3HffLJJ1x//fU8/PDDnHPOOdx+++28/fbbAHuBOuCBcGpHu8R5L+Ltg+5PuHuhuxeOGTOm55UQ6QdK+mmgsbGR1atXs337dpqamti+fTurV6+msbEx2UVLCU1NTVx//fXcdNNNfPnLXwZg3LhxZGRkxE95klj3DcRa6ucnXJ4HfHCa+BEg28yGtYmLpCQl/TQwadIkbrrpplZ9+jfddBOTJk3q+uI05+6UlpaSn5/P4sWLW+J1dXWJp30J2BOePw/caGZZZnYBMBF4FXgNmBhG6mQSu9n7fNgTejvwlXB9CfDcQNZJpC80IzcNlJWVUVZWRkVFBTNmzGDHjh2UlpbqRi7w8ssv89RTT/HpT3+aKVOmAHDfffdRVVVFdXU1xEbiFAFfB3D3t8zsGWLdPieBO9y9GcDMFgCbgQyg0t3fCj9mKbDezL4H7AYqBq2CIj2kpJ8GiouL+c1vfsOVV17JiRMnyMrK4mtf+xrFxcXJLlrSzZgxg1hjvLWrrooNyzezve5+TeJ77l4OtPuNGYZ1buwg/g7/6B4SSWnq3kkDVVVVbNiwgRdeeIHGxkZeeOEFNmzYoHH6ItKOkn4aKC8vp6KiotXonYqKCnXviEg7SvppoKamhhkzZrSKzZgxg5qamiSVSERSlZJ+GsjPz2fHjh2tYjt27CA/Pz9JJRKRVKUbuWmgrKyMr371q4wcOZI//elP/PM//zPHjx9vWVxMRCROLf0009FIFRGROCX9NFBeXs78+fMZOXIkZsbIkSOZP3++buSKSDvq3kkDe/fu5dChQ5x11lkAHD9+nB/96Ef85S9/SXLJRCTVqKWfBjIyMjh16hSVlZU0NDRQWVnJqVOnEteWEREBupH0w7KzH5rZnoTYXWb2fthxqE+7DknfnTx5st2KmpmZmZw8ebKTK0QkqrrT0v8JsR2E2noo7DjU112HpB/ceuutrRZcu/XWW5NdJBFJQV326bv7r81sQjc/r2XXIeBdM4vvOgRh1yEAM1sfztUuH/0gLy+PH//4xzz99NMtC67NnTuXvLy8ZBdNRFJMX/r0F5jZm33cdagd7S7UcytXrqS5uZl58+aRlZXFvHnzaG5uZuXKlckumoikmN4m/ceBi4Ap9G3XofZB7S7UY8XFxaxatarVkM1Vq1ZplU0RaadXQzbd/VD8uZk9Cfzf8LKz3YU4TVz6QXFxsZK8iHSpVy19M8tNeNnrXYd6X2wREemN7gzZrAJ+C/yLmdWaWSmw0sx+b2ZvEtt16E6I7ToExHcd2kTYdcjdTwLxXYdqgGcSdh2SflBVVUVBQQEZGRkUFBRoLX0R6VB3Ru901GfQ6XZwPd11SPquqqqKRYsWMXLkSNyd48ePs2jRIgB1+YhIK5qRmwaWLFlCY2Njq1hjYyNLlixJUolEJFUp6aeB2traltU1zWIDpdyd2traZBZLRFKQkn6aGDZsWKu1d4YN01p6AAcPHqSoqIj8/HwmT57cssdAfX09M2fOBCgwsy3xuSYW80hYLuRNM5sa/ywzKzGzfeEoSYh/Ltzj2h+u7WiIskhKUNJPE23X0de6+jHDhg3jgQceoKamhp07d/LYY4+xd+9eVqxYwRVXXAGxkWdbgfh6UFcSG3U2EZhPbE4KZpYDLAemE5tlvjxhUuLj4dz4dR0tWyKSEpT000RDQwOzZ88mMzOT2bNn09DQkOwipYTc3FymTo011s8++2zy8/N5//33ee655ygpaWmsrwWuC8+vBdZ5zE4gOwxRng1scfd6dz8KbAHmhPfOcfffeuw37bqEzxJJOUr6aSAnJ4eGhgbOPfdczjjjDM4991waGhrIyclJdtFSyoEDB9i9ezfTp0/n0KFD5ObGppu4ex0wNpzW06VExofnbePtaIkRSQVK+mngzDPPZNSoUYwYMQJ3Z8SIEYwaNYozzzwz2UVLGZ988gnXX389Dz/8MOecc87pTu3pUiJaYkSGFCX9NPDBBx9QWFjIe++9h7vz3nvvUVhYyAcfaKULgKamJq6//npuuukmvvzlLwMwbtw46urqgJYZ5h+G0ztbSuR08bwO4iIpSUk/DWRnZ7N161bGjRvHGWecwbhx49i6dSvZ2dnJLlrSuTulpaXk5+ezePHilvg111zD2rVr4y9LgOfC8+eBm8MonkuAj0L3z2ZglpmNDjdwZwGbw3sfm9klYdTOzQmfJZJylPTTwLFjxzAzvv3tb/Pxxx/z7W9/GzPj2LFjyS5a0r388ss89dRTbNu2jSlTpjBlyhQ2btzIsmXL2LJlC0ABMBNYES7ZCLwD7AeeBP4DwN3rgXuJrSP1GnBPiAHcDvyfcM3bwAuDUzuRnrNUHtpXWFjou3btSnYxUp6ZsWTJEjZs2EBNTQ35+flcffXVrFy5UkM3u2Bmr7t74WD/3NN9tycs29Crzzyw4uq+FEnSyOm+12rpp4nzzjuPPXv20NzczJ49ezjvvPOSXSQRSUFK+mkgJyeHpUuXkpubS0ZGBrm5uSxdulRDNkWkHSX9NDB37lwA/vznP3Pq1Cn+/Oc/t4qLiMQp6aeBZ599lhEjRjB8+HAAhg8fzogRI3j22WeTXDIRSTVK+mmgtraWUaNGsXnzZhobG9m8eTOjRo3SKpsi0o6SfppYvHgxRUVFDB8+nKKiolZj0kVE4pT008SDDz7I9u3baWpqYvv27Tz44IPJLpKIpCAtup4G8vLyeP/997n88stbYmZGXl7eaa4SkShSSz8NmFnLQmtAy8Jr2stDRNpSSz8NHDx4kM9+9rM0NjZSU1PDRRddRGZmJrt370520UQkxSjpp4lf/epXrWbhHjlyBC3fKyJtKemnic9//vPU1dVx4sQJsrKyWjYIERFJpKSfBnJycjhw4EBLH35jYyMHDhzQMgwi0o5u5KaB+BLK8RU1449aWllE2lLSTwOnTp0CIDMzEzMjMzOzVVxEJE7dO2mksbGx1aOISFtq6aeReJ++xueLSGeU9NNI2z59EZG2lPRFRCJESV9EJEK6TPpmVmlmH5rZnoRYjpltMbN94XF0iJuZPWJm+83sTTObmnBNSTh/n5mVDEx1RETkdLrT0v8JMKdNbBmw1d0nAlvDa4ArgYnhmA88DrFfEsByYDowDVge/0UhMtDmzZvH2LFjKSgoaIndddddjB8/HmCSmVWb2VXx98zsO6Hh8kczm50QnxNi+81sWUL8AjN7JTRofmZmmYNUNZEe6zLpu/uvgfo24WuBteH5WuC6hPg6j9kJZJtZLjAb2OLu9e5+FNhC+18kIgPilltuYdOmTe3id955J8Bed5/i7hsBzGwScCMwmdh39IdmlmFmGcBjxBo2k4DicC7A/cBDoRF0FCgd4CqJ9Fpv+/THuXsdQHgcG+LjgYMJ59WGWGfxdsxsvpntMrNdhw8f7mXxRP7h0ksv7cmSFNcC6939hLu/C+wn9tfpNGC/u7/j7o3AeuBai42PvRz4ebg+sREkknL6+0ZuRwPE/TTx9kH3J9y90N0LtUqkDKRHH30UYt07lQndjT1tuJwLHHP3k23i7ahBI6mgt0n/UOi2ITx+GOK1wPkJ5+UBH5wmLpIUt99+O2+//TbAXqAOeCC81dOGixo0MqT0Nuk/D8RH4JQAzyXEbw6jeC4BPgrdP5uBWWY2OrSoZoWYSFKMGzeOjIyM+MsniXXfQM8bLkeI3bsa1iYukpK6M2SzCvgt8C9mVmtmpcAKYKaZ7QNmhtcAG4F3iPWDPgn8B4C71wP3Aq+F454QE0mKurq6xJdfAuJDkp8HbjSzLDO7gNhItFeJfW8nhpE6mcRu9j7vsenP24GvhOsTG0EiKafLBdfcvbiTt67o4FwH7ujkcyqByh6VTqQfFBcX89JLL3HkyBHy8vK4++67eemll6iurobYSJwi4OsA7v6WmT1DrNvnJHCHuzcDmNkCYn+hZgCV7v5W+BFLgfVm9j1gN1AxmPUT6Qmtsilpr6qqql2stDQ2qtLM9rr7NYnvuXs5UN72mjCsc2MH8Xf4R/eQSErTMgwiIhGipC8iEiFK+iIiEaKkLyISIUr6IiIRoqQvIhIhSvoiIhGipC8iEiFK+iIiEaKkLyISIUr6IiIRoqQvIhIhSvoiIhGipC8iEiFK+iIiEaKkLyISIUr6IiIRoqQvIhIh2i5RJE1MWLahV9cdWHF1P5dEUpla+iIiEaKkL2lv3rx5jB07loKCgpZYfX09M2fOBCgwsy1mNhrAYh4xs/1m9qaZTY1fY2YlZrYvHCUJ8c+Z2e/DNY+YmQ1i9UR6RElf0t4tt9zCpk2bWsVWrFjBFVdcAbAH2AosC29dCUwMx3zgcQAzywGWA9OBacDy+C+KcM78hOvmDGB1RPpESV/S3qWXXkpOTk6r2HPPPUdJSUtjfS1wXXh+LbDOY3YC2WaWC8wGtrh7vbsfBbYAc8J757j7b93dgXUJnyWScpT0JZIOHTpEbm4uAO5eB4wNb40HDiacWhtip4vXdhBvx8zmm9kuM9t1+PDh/qiGSI8p6Yu01lF/vPci3j7o/oS7F7p74ZgxY/pQRJHeU9KXSBo3bhx1dXUAhC6aD8NbtcD5CafmAR90Ec/rIC6SkpT0JZKuueYa1q5dG39ZAjwXnj8P3BxG8VwCfBS6fzYDs8xsdLiBOwvYHN772MwuCaN2bk74LJGUo8lZkvaKi4t56aWXOHLkCHl5edx9990sW7aMG264AaAA+Aj4t3D6RuAqYD/wN+BWAHevN7N7gdfCefe4e314fjvwE+CfgBfCIZKSlPQl7VVVVXUY37p1K2a2x92viMfCCJw7Ojrf3SuByg7iu4j98hBJeereERGJkD4lfTM7EGYiVpvZrhDLCTMc93V3pqOIiAyO/mjpF7n7FHcvDK+XAVvdfSLdmOkovWNmLUd3zhMRgYHp3rmW2AxH6N5MR+kFd285unOeiAj0Pek78Csze93M5ofYuDCMrbszHVvRrEURkYHT19E7X3D3D8xsLLDFzP5wmnO7NXPR3Z8AngAoLCxUE7Ub3L3DLhy18EWkrT619N39g/D4IfBfxFYfPBTvtunmTEfpB4ndOOrSEZHO9Drpm9lIMzs7/pzYDMU9xGY0xpcv7M5MRxERGSR96d4ZB/xX6FYYBjzt7pvM7DXgGTMrBf5EFzMdRURk8PQ66bv7O8DFHcT/AlzRQbzTmY4iIjI4NCNXRCRClPRFRCJESV9EJEKU9EVEIkRJX0QkQpT0RUQiRElfRCRClPRFRCJESV9EJEKU9EVEIkRJX6Lu0/2x5aeZlYTz95lZSWc/TCTZlPRTXE5OTqutEbs6gG6fm5OTk+TapYw+bflpZjnAcmA6seXFl8d/UYikGiX9FHf06NFWWyP253H06NFkVy9V9XTLz9nAFnevd/ejwBZgzmAXWqQ7lPRF+r7lp7YClSGjr9sligx1f3D3qX3c8lNbgcqQoZa+RF0T9HnLT20FKkOGkr5E1vHjxyH8P9DHLT83A7PMbHS4gTsrxERSjrp3JLIOHToE8K9m9gZ92PLT3evN7F7gtXDePe5eP3g1Eek+JX2JrAsvvBBgb8JQTaB3W366eyVQOQDFFOlXSvopzpefA3eNGrjPFpFIUdJPcXb3X4k1MAfgs83wuwbko0UkRelGrohIhCjpi4hEiLp3hoD4mjr9bfRoLQ8jEjVK+imup/35ZjZg9wBEZOhT946ISIQo6YuIRIi6d0QibsKyDT2+5sCKqwegJDIY1NIXEYkQJX0RkQgZ9KRvZnPM7I9hn9FlXV8hIiL9ZVCTvpllAI8R22t0ElBsZpMGswwiIlE22C39acB+d3/H3RuB9cT2HRURkUEw2Em/y71EtY9o95hZh0dn74mIwOAn/S73EnX3J9y90N0Lx4wZM0jFGnrcvUeHiAgMftLXXqIiIkk02En/NWCimV1gZpnAjcT2HRURkUEwqDNy3f2kmS0gtml0BlDp7m8NZhlEpO96M4sXNJM3FQz6MgzuvpHYBtMiIjLINCNXRCRClPRF+oFmmstQoaQv0keaaS5DiZZWFum7lpnmAGYWn2m+N6mlSkG6AZx8KZ30X3/99SNm9l6yyzHEnAccSXYhhpD/3g+f0dFM8+ltTzKz+cD88PITM/tjJ5+Xzv+Gvaqb3T8AJRkYqfJv1+n3OqWTvrtrSm4Pmdkudy9MdjkipsuZ5hCbbQ480eWHpfG/YTrXDYZG/dSnL9J3mmkuQ4aSvkjfaaa5DBkp3b0jvdJl94H0rwGYaZ7O/4bpXDcYAvUzrcAoIhId6t4REYkQJX0RkQhR0k8DZlZpZh+a2Z5kl0V6b6gu5dDR98/Mcsxsi5ntC4+jQ9zM7JFQxzfNbGrCNSXh/H1mVpKMurRlZueb2XYzqzGzt8xsUYgP3fr1dAcmHal3AJcCU4E9yS6Ljl7/G2YAbwMXApnAG8CkZJerm2Vv9/0DVgLLwvNlwP3h+VXAC8TmNlwCvBLiOcA74XF0eD46BeqWC0wNz88G/h+xpTaGbP3U0k8D7v5roD7Z5ZA+aVnKwd0bgfhSDimvk+/ftcDa8HwtcF1CfJ3H7ASyzSwXmA1scbA2++kAAAFHSURBVPd6dz8KbAHmDHzpT8/d69z9d+H5x0ANsRnYQ7Z+SvoiqaGjpRzGJ6ks/WGcu9dBLHECY0O8s3qmfP3NbALwWeAVhnD9lPRFUkO3lnJIA53VM6Xrb2ZnAb8AvuHufz3dqR3EUqp+SvoiqSHdlnI4FLo1CI8fhnhn9UzZ+pvZcGIJ/6fu/ssQHrL1U9IXSQ3ptpTD80B8hEoJ8FxC/OYwyuUS4KPQPbIZmGVmo8NImFkhllRmZkAFUOPuDya8NXTrl+y74zr6fgBVQB3QRKxFUZrsMuno1b/jVcRGh7wNlCW7PD0od7vvH3AusBXYFx5zwrlGbMOZt4HfA4UJnzMP2B+OW5Ndr1CmGcS6Yd4EqsNx1VCun5ZhEBGJEHXviIhEiJK+iEiEKOmLiESIkr6ISIQo6YuIRIiSvohIhCjpi4hEyP8Hf+5mly2+knsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# محاسبه میانگین و انحراف استاندارد نظرات\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
    "# رسم طول نظرات با نمودارهای جعبه ای و هیستاگرام\n",
    "pyplot.subplot(121)\n",
    "pyplot.boxplot(result)\n",
    "pyplot.subplot(122)\n",
    "pyplot.hist(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) ساخت مدل شبکه عصبی MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 1225, 446, 2, 45, 2174, 84, 2, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 2, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 2, 5, 4241, 18, 4, 2, 2, 250, 11, 1818, 2, 4, 4217, 2, 747, 1115, 372, 1890, 1006, 541, 2, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "         list([1, 1446, 2, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 2, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 2, 2, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 2, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0], dtype=int64)),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 1668, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 2, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 2, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 2, 2, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 2, 185, 132, 1988, 2, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 2, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 2, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 2, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 2, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 2, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 2, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 1239, 2, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 2, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 2, 2, 3292, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 2, 2, 4, 4770, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 2, 5, 2, 68, 1830, 19, 2, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 2, 2, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 2, 7, 15, 2, 2, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 2, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 2, 9, 133, 1810, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 2, 3406, 718, 2, 9, 6, 2, 17, 210, 5, 3281, 2, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 1441, 2, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0], dtype=int64)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only Load the Top 5,000 words in the IMDB Review.\n",
    "imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the Keras utility to truncate or pad the dataset to a length of 500 for each observation using the sequence.pad sequences() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x14062fc79b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The output of this first layer would be a matrix with the size 32 * 500 for a given movie review training or test pattern in integer format\n",
    "Embedding(5000, 32, input_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 48s 2ms/step - loss: 0.5019 - accuracy: 0.7175 - val_loss: 0.2940 - val_accuracy: 0.8743\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 39s 2ms/step - loss: 0.1815 - accuracy: 0.9310 - val_loss: 0.3318 - val_accuracy: 0.8575\n",
      "Accuracy: 85.75%\n"
     ]
    }
   ],
   "source": [
    "# استفاده از MLP برای حل مسئله IMDB\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# برای حفظ اعتبار مدل\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# با کار واژگان برتر\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation= 'relu' ))\n",
    "model.add(Dense(1, activation= 'sigmoid' ))\n",
    "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "print(model.summary())\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128,\n",
    "verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ساخت مدل شبکه عصبی کانولوشنی یک بعدی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# CNN for the IMDB problem\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load, Split and Pad IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\keras\\datasets\\imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 324s 19us/step\n"
     ]
    }
   ],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "test_split = 0.33\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=32, kernel_size=3, padding=\"same\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length= max_words))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode= 'same' ,\n",
    "            activation= 'relu' ))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation= 'relu' ))\n",
    "model.add(Dense(1, activation= 'sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ShahinN\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 133s 5ms/step - loss: 0.4304 - accuracy: 0.7744 - val_loss: 0.2730 - val_accuracy: 0.8852\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 147s 6ms/step - loss: 0.2033 - accuracy: 0.9224 - val_loss: 0.2690 - val_accuracy: 0.8876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f09b299668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.76%\n"
     ]
    }
   ],
   "source": [
    "#Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
